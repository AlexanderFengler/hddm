{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hddm\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "from kabuki.analyze import gelman_rubin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set number of synthetic subjects and amount of trial to generate per subject\n",
    "subjects = 4\n",
    "trials = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create array with all combinations of three values for a, t, scaler and alpha\n",
    "x = np.array([(a, t, scaler, alpha)\n",
    "              for a in np.linspace(1.5,2.5,num=3) \n",
    "              for t in np.linspace(0.3,0.5,num=3) \n",
    "              for scaler in np.linspace(1.5,3,num=3) \n",
    "              for alpha in np.linspace(0.15,0.45,num=3)\n",
    "              ])\n",
    "f = pd.DataFrame(data=x,columns=['a','t', 'scaler', 'alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate data, estimate model and save traces and convergence info for all combinations of models\n",
    "#this will take a while, so sending these as jobs on a cluster is recommended\n",
    "for i in range(f.shape[0]):\n",
    "    print(i)\n",
    "    data = hddm.generate.gen_rand_rlddm_data(a=f.a[i],alpha=f.alpha[i],scaler=f.scaler[i],t=f.t[i],size=trials,subjs=subjects,p_upper=0.75,p_lower=0.25)\n",
    "    data['q_init'] = 0.5\n",
    "    models = []\n",
    "    for a in range(3):  \n",
    "        m = hddm.HDDMrl(data=data)\n",
    "        m.sample(30,burn=15,dbname='traces.db',db='pickle')\n",
    "        models.append(m)\n",
    "    gelman = gelman_rubin(models)\n",
    "    gelman = pd.DataFrame.from_dict(gelman,orient='index')\n",
    "    convergencename = 'convergence_model%s.csv'%(i)\n",
    "    gelman.to_csv(convergencename)\n",
    "    traces = m.get_traces()\n",
    "    filename = 'traces_model%s.csv'%(i)\n",
    "    traces.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gelmans = hddm.load_csv('convergence_model0.csv').T\n",
    "gelmans.columns = gelmans.iloc[0]\n",
    "gelmans = gelmans.drop('Unnamed: 0',axis=0)\n",
    "conv = gelmans\n",
    "\n",
    "for i in range(1,f.shape[0]):\n",
    "    filename = 'convergence_model%i.csv' %(i)\n",
    "    gelmans = hddm.load_csv(filename).T\n",
    "    gelmans.columns = gelmans.iloc[0]\n",
    "    gelmans = gelmans.drop('Unnamed: 0',axis=0)\n",
    "    conv = conv.append(gelmans)            \n",
    "conv = conv.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion parameters that did not converge when not using find_starting and sample at 3000 and burnin 1500\n",
    "conv = pd.melt(conv, var_name=\"Parameter\", value_name=\"Value\")\n",
    "np.mean(conv['Value']>1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot parameter recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = hddm.load_csv('traces_model0.csv')\n",
    "tg = traces[traces.columns.drop(list(traces.filter(regex='subj')))]\n",
    "means = pd.DataFrame(tg.mean(axis=0)).T\n",
    "means.append(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty Dataframe with column names only\n",
    "means = pd.DataFrame(columns=['Unnamed: 0','a','a_std','alpha','alpha_std','t','t_std','v','v_std','cor_at'])\n",
    "\n",
    "for i in range(1,f.shape[0]):\n",
    "    filename = 'traces_model%i.csv' %(i)\n",
    "    traces = hddm.load_csv(filename)\n",
    "    tg = traces[traces.columns.drop(list(traces.filter(regex='subj')))]\n",
    "    summ = pd.DataFrame(tg.mean(axis=0)).T\n",
    "    summ['cor_at'] = np.corrcoef(tg['a'],tg['t'])[1,0]\n",
    "    means = means.append(summ)\n",
    "means.columns = ['trace','e_a','e_a_std','e_alpha','e_alpha_std','e_t','e_t_std','e_v','e_v_std','cor_at']\n",
    "means['e_alphaT'] = np.exp(means['e_alpha'])/(1+np.exp(means['e_alpha']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make in long format to plot all in one figure\n",
    "f.reset_index(drop=True, inplace=True)\n",
    "means.reset_index(drop=True, inplace=True)\n",
    "a=pd.DataFrame({'sim':f['a'],'parameter':'a','est':means['e_a']})\n",
    "t=pd.DataFrame({'sim':f['t'],'parameter':'t','est':means['e_t']})\n",
    "alpha=pd.DataFrame({'sim':f['alpha'],'parameter':'alpha','est':means['e_alphaT']})\n",
    "scaler=pd.DataFrame({'sim':f['scaler'],'parameter':'scaler','est':means['e_v']})\n",
    "long = a\n",
    "long = long.append(t)\n",
    "long = long.append(scaler)\n",
    "long = long.append(alpha)\n",
    "long['error'] = np.absolute(long['est']-long['sim'])\n",
    "long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot absolute error\n",
    "g = sns.catplot(x='parameter',y='error',sharey=False,data=long)\n",
    "g.savefig('absolute_error.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hline(y,**kwargs):\n",
    "    data = kwargs.pop(\"data\") #get the data frame from the kwargs\n",
    "    plt.axhline(y=y, c='black',linestyle='-',zorder=-1) #zorder places the line underneath the other points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot NDT\n",
    "g = sns.catplot(x='sim',y='est',data=long[long.parameter=='t'])\n",
    "g.map_dataframe(plot_hline,y=0.3)\n",
    "g.map_dataframe(plot_hline,y=0.4)\n",
    "g.map_dataframe(plot_hline,y=0.5)\n",
    "plt.ylim(0.25,0.55)\n",
    "g.fig.suptitle(\"Non-decision time\")\n",
    "g.set_axis_labels(\"Simulated NDT\", \"Estimated NDT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Decision threshold\n",
    "g = sns.catplot(x='sim',y='est',data=long[long.parameter=='a'])\n",
    "g.map_dataframe(plot_hline,y=1.5)\n",
    "g.map_dataframe(plot_hline,y=2)\n",
    "g.map_dataframe(plot_hline,y=2.5)\n",
    "g.fig.suptitle(\"Decision threshold\")\n",
    "g.set_axis_labels(\"Simulated threshold\", \"Estimated threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot alpha\n",
    "g = sns.catplot(x='sim',y='est',data=long[long.parameter=='alpha'])\n",
    "g.map_dataframe(plot_hline,y=0.15)\n",
    "g.map_dataframe(plot_hline,y=0.3)\n",
    "g.map_dataframe(plot_hline,y=0.45)\n",
    "g.fig.suptitle(\"Learning rate\")\n",
    "g.set_axis_labels(\"Simulated alpha\", \"Estimated alpha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot scaling\n",
    "g = sns.catplot(x='sim',y='est',data=long[long.parameter=='scaler'])\n",
    "g.map_dataframe(plot_hline,y=1.5)\n",
    "g.map_dataframe(plot_hline,y=2.25)\n",
    "g.map_dataframe(plot_hline,y=3)\n",
    "g.fig.suptitle(\"Scaling drift rate\")\n",
    "g.set_axis_labels(\"Simulated scaling\", \"Estimated scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:updated_hddm_master]",
   "language": "python",
   "name": "conda-env-updated_hddm_master-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
